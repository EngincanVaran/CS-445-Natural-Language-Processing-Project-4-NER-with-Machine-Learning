# -*- coding: utf-8 -*-
"""project04.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10M2kzCiSTAsbTzAh36gSmqKKWlsgVhF0
"""

# Commented out IPython magic to ensure Python compatibility.
# %%shell
# jupyter nbconvert --to html "/content/project04.ipynb"

!pip install sklearn-crfsuite

import pandas as pd
import numpy as np
import re

import sklearn_crfsuite
from sklearn_crfsuite import scorers
from sklearn_crfsuite import metrics
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical

from itertools import chain

import nltk
import sklearn
import scipy.stats
from sklearn.metrics import make_scorer
from sklearn.model_selection import RandomizedSearchCV, cross_val_score
from collections import Counter

"""# Read NE.txt"""

path = "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/NE.txt"

dataFile = open(path, "r")
dataLines = dataFile.readlines()

data = []
rawData = []

for line in dataLines:
    temp = line.replace("  ", " ")
    temp = temp.replace(" '", "'")
    temp = temp.replace("\n","")
    # temp2 = re.sub("\'","'", temp)
    rawData.append(temp)
    
    temp = re.sub(r'<.*?>',"", temp)
    data.append(temp)

data[0]

rawData[0]

paths = [ 
         "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/Organization Database/organization_top_companies.txt",
        "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/Organization Database/organization_turkey_top.txt",
        "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/Organization Database/organization_turkish_banks.txt",
        "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/Organization Database/organization_turkish_kurum.txt",
]

orgData = []

for path in paths:
    orgFile = open(path, "r")
    orgData += orgFile.read().splitlines()
    orgFile.close()

for line in orgData:
    if line == "":
        orgData.remove("")

orgData[-10:]

"""# Read NE.ma.txt and Feature Mapping"""

def printResults(res):
    for key, value in res.items():
        print("Results for:", key)
        print("\tFlat_Accuracy:", value[0])
        print("\tFlat_F1_Score:", value[1])
        print("\tFlat_Precision:", value[2])
        print("\tFlat_Recall:", value[3])

def mapFeatures(word, ma, BOS, counter):
    
    stemIndex = ma.find("+")
    stem = ma[:stemIndex]

    ma = ma[stemIndex+1:]
    
    if counter > 0:
        if "DB" in ma:
            POSINDEX = ma.find("DB")
            POS = ma[POSINDEX+3:ma.find("+", POSINDEX+3)]
        else:
            POS = ma[:ma.find("+")]

    if counter > 1:
        PROP = False
        if "Prop" in ma:
            PROP = True

    if counter > 2:
        if "Nom" in ma:
            NounCase = "Nom"
        elif "Acc" in ma:
            NounCase = "Acc"
        elif "Dat" in ma:
            NounCase = "Dat"
        elif "Abl" in ma:
            NounCase = "Abl"
        elif "Loc" in ma:
            NounCase = "Loc"
        elif "Gen" in ma:
            NounCase = "Gen"
        elif "Ins" in ma:
            NounCase = "Ins"
        elif "Equ" in ma:
            NounCase = "Equ"
        else:
            NounCase = False

    if counter > 3:
        OCS = "LC"
        if word.isupper() and not BOS:
            OCS = "UC"

    if counter > 4:
        if "DB" in ma:
            POSINDEX = ma.find("DB")
            INFIndex = ma.find("+", POSINDEX+3)
            INF = ma[INFIndex+1:]
        else:
            INFIndex = ma.find("+")
            INF = ma[INFIndex+1:]

    if counter > 5:
        inORG = False
        for line in orgData:
            if word.upper() in line.upper():
                inORG = True

    if counter == 0:
        features = {
            'Stem': stem,       # stem
            'BOS': BOS,         # start of sentence
        }
    elif counter == 1:
        features = {
            'Stem': stem,       # stem
            'POS': POS,         # part-of-speech
            'BOS': BOS,         # start of sentence
        }
    elif counter == 2:
        features = {
            'Stem': stem,       # stem
            'POS': POS,         # part-of-speech
            'PROP': PROP,       # proper noun
            'BOS': BOS,         # start of sentence
        }
    elif counter == 3:
        features = {
            'Stem': stem,       # stem
            'POS': POS,         # part-of-speech
            'PROP': PROP,       # proper noun
            'NCS': NounCase,    # noun-case
            'BOS': BOS,         # start of sentence
        }
    
    elif counter == 4:
        features = {
            'Stem': stem,       # stem
            'POS': POS,         # part-of-speech
            'PROP': PROP,       # proper noun
            'NCS': NounCase,    # noun-case
            'OCS': OCS,
            'BOS': BOS,         # start of sentence
        }
    
    elif counter == 5:
        features = {
            'Stem': stem,       # stem
            'POS': POS,         # part-of-speech
            'PROP': PROP,       # proper noun
            'NCS': NounCase,    # noun-case
            'OCS': OCS,
            'INF': INF,
            'BOS': BOS,         # start of sentence
        }

    elif counter > 5:
        features = {
            'Stem': stem,       # stem
            'POS': POS,         # part-of-speech
            'PROP': PROP,       # proper noun
            'NCS': NounCase,    # noun-case
            'OCS': OCS,
            'INF': INF,
            'BOS': BOS,         # start of sentence
            'INORG': inORG,     # is in datalist
        }

    return features

for i in range(7):
    # ('Müzik', 'müzik+Noun+A3sg+Pnon+Nom'),
    print( mapFeatures("Müzik", 'müzik+Noun+A3sg+Pnon+Nom', True, i), "\n")

# # ('hazırlanın', 'hazırla+Verb^DB+Verb+Reflex+Pos+Imp+A2pl') hazırlanın
# print( mapFeatures("hazırlanın", 'hazırla+Verb^DB+Verb+Reflex+Pos+Imp+A2pl', False, 5), "\n")

# # 'olan', 'ol+Verb+Pos^DB+Adj+PresPart') olan
# print( mapFeatures("olan", 'ol+Verb+Pos^DB+Adj+PresPart', False, 4))

print( mapFeatures("Teknik", 'teknik+Noun+Prop+A3sg+Pnon+Nom', False, 6) )

def maParser(line):
    firstSpace = line.find(" ")
    secondSpace = line.find(" ", firstSpace+1)
    lineNum = int(line[:firstSpace])
    word = line[firstSpace+1:secondSpace]
    ma = line[secondSpace+1:]

    return lineNum, word, ma

def getLabel(line, word):

    if line.find("<") == -1:
        return "O"

    while line.find("<") != -1:
        start_1 = line.find("<")
        end_1 = line.find(">")
        temp = line[start_1:end_1-1]
        typeIndex = temp.find("TYPE")

        start_2 = line.find("<", end_1+1)
        
        labelList = line[end_1+1:start_2].split()

        if word in labelList:
            if labelList[0] == word:
                labelType = temp[typeIndex+6:]
                labelType = "B-" + labelType
                break
            else:
                labelType = temp[typeIndex+6:]
                labelType = "I-" + labelType
                break
        else:
            labelType = "O"
        
        end_2 = line.find(">", start_2+1)
        line = line[end_2+3:]

    return (labelType)

line = 'Müzik Şenliği\'ne hazırlanın  <b_enamex TYPE="ORGANIZATION">POZİTİF ve Açık Radyo<e_enamex>  işbirliğiyle düzenlenecek olan  <b_enamex TYPE="LOCATION">İstanbul<e_enamex>'
print( getLabel( line, "İstanbul") )
print( getLabel( line, "POZİTİF") )
print( getLabel( line, "Radyo") )

"""# Run All"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# includedFeatures = [ "Stem", "POS", "PROP", "NCS", "OCS", "INF", "INORG"]
# 
# path = "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/NE.ma.txt"
# 
# maFile = open(path, "r")
# maLines = maFile.read().splitlines()
# 
# results = {}
# avgResults = {}
# 
# for counter in range(7):
#     IncFeatures = ""
#     for index in range(counter+1):
#         IncFeatures += includedFeatures[index] + " "
# 
#     IncFeatures += "BOS"
# 
#     print("***\nStarted for counter:", counter, ":", IncFeatures)
# 
#     maData = []
#     i = 0
#     for line in maLines:
#         lineNum, word, ma = maParser(line)
#         if lineNum > len(maData):
#             maData.append( [line] )
#         else:
#             maData[lineNum-1].append(line)
# 
#     X = []
#     y = []
# 
#     prevLine = 1
#     index = 0
#     for line in maData:
#         temp_X = []
#         temp_y = []
#         BOS = True
#         for word in line:
#             lineNum, word, ma = maParser(word)
#             temp_X.append( mapFeatures(word, ma, BOS, counter) )
#             temp_y.append( getLabel(rawData[lineNum-1], word))
#             BOS = False
#         X.append(temp_X)
#         y.append(temp_y)
# 
#     X_fold0 = []
#     X_fold1 = []
#     X_fold2 = []
#     X_fold3 = []
#     X_fold4 = []
# 
#     y_fold0 = []
#     y_fold1 = []
#     y_fold2 = []
#     y_fold3 = []
#     y_fold4 = []
# 
#     X_folds = [ X_fold0, X_fold1, X_fold2, X_fold3, X_fold4 ]
#     y_folds = [ y_fold0, y_fold1, y_fold2, y_fold3, y_fold4 ]
# 
#     for index, sentence in enumerate(X):
#         X_folds[index % 5].append(sentence)
#     
#     for index, label in enumerate(y):
#         y_folds[index % 5].append(label)
# 
#     print("\tFolding is done.")
# 
#     foldAverages = [0, 0, 0, 0]
# 
#     for testFold in range(5):
#         print("\t\tTestfold:", testFold)
#         loopName = str(counter) + "_" + str(testFold)
#         
#         X_train = []
#         y_train = []
# 
#         for index, fold in enumerate(X_folds):
#             if index != testFold:
#                 X_train += fold
# 
#         for index, labels in enumerate(y_folds):
#             if index != testFold:
#                 y_train += labels
# 
#         X_test = X_folds[testFold]
#         y_test = y_folds[testFold]
# 
#         crf = sklearn_crfsuite.CRF(
#             algorithm='lbfgs',
#             c1=0.1,
#             c2=0.1,
#             max_iterations=100,
#             all_possible_transitions=True, )
#         
#         crf.fit(X_train, y_train)
#         
#         labels = list(crf.classes_)
#         labels.remove("O")
#         sorted_labels = sorted( labels, key=lambda name: (name[1:], name[0]))
# 
#         predictions = crf.predict(X_test)
# 
#         acc = metrics.flat_accuracy_score(y_test, predictions)
#         f1 = metrics.flat_f1_score(y_test, predictions, average="weighted", labels=sorted_labels)
#         precision = metrics.flat_precision_score(y_test, predictions, average="weighted", labels=sorted_labels)
#         recall = metrics.flat_recall_score(y_test, predictions, average="weighted", labels=sorted_labels)
# 
#         foldAverages[0] += acc
#         foldAverages[1] += f1
#         foldAverages[2] += precision
#         foldAverages[3] += recall
#         results[loopName] = [ acc, f1, precision, recall]
# 
#         # print( "TestFold is:", testFold ," --> Flat f1 score:", metrics.flat_f1_score(y_test, predictions, average="weighted") )
#         print( metrics.flat_classification_report( y_test, predictions, labels=sorted_labels, digits=3) )
# 
#     avgResults[IncFeatures] = [
#                                foldAverages[0] / 5,
#                                foldAverages[1] / 5,
#                                foldAverages[2] / 5,
#                                foldAverages[3] / 5,
#     ]
# 
#     print("***\n")
# 
# 
#

printResults(avgResults)

printResults(results)

"""# What Model Learns?"""

maData = []
i = 0
for line in maLines:
    lineNum, word, ma = maParser(line)
    if lineNum > len(maData):
        maData.append( [line] )
    else:
        maData[lineNum-1].append(line)

X = []
y = []

prevLine = 1
index = 0
for line in maData:
    temp_X = []
    temp_y = []
    BOS = True
    for word in line:
        lineNum, word, ma = maParser(word)
        temp_X.append( mapFeatures(word, ma, BOS, 6) )
        temp_y.append( getLabel(rawData[lineNum-1], word))
        BOS = False
    X.append(temp_X)
    y.append(temp_y)

crf = sklearn_crfsuite.CRF(
            algorithm='lbfgs',
            c1=0.1,
            c2=0.1,
            max_iterations=100,
            all_possible_transitions=True, )
        
crf.fit(X, y)

def print_transitions(trans_features):
    for (label_from, label_to), weight in trans_features:
        print("%-6s -> %-7s %0.6f" % (label_from, label_to, weight))

print("Top likely transitions:")
print_transitions(Counter(crf.transition_features_).most_common(20))

print("\nTop unlikely transitions:")
print_transitions(Counter(crf.transition_features_).most_common()[-20:])

countDic = {
    "O": 0,
    "B-PERSON": 0,
    "I-PERSON": 0,
    "B-ORGANIZATION": 0,
    "I-ORGANIZATION": 0,
    "B-LOCATION": 0,
    "I-LOCATION": 0,
}


for line in y:
    for label in line:
        countDic[label] += 1

countDic

"""# K-Folds And Run All"""

path = "/content/drive/MyDrive/2020-2021 401/CS 445/Projects/CS 445 Project 4/NE.ma.txt"

maFile = open(path, "r")
maLines = maFile.read().splitlines()

maData = []
i = 0
for line in maLines:
    lineNum, word, ma = maParser(line)
    if lineNum > len(maData):
        maData.append( [line] )
    else:
        maData[lineNum-1].append(line)

X = []
y = []

prevLine = 1
index = 0
for line in maData:
    temp_X = []
    temp_y = []
    BOS = True
    for word in line:
        lineNum, word, ma = maParser(word)
        temp_X.append( mapFeatures(word, ma, BOS) )
        temp_y.append( getLabel(rawData[lineNum-1], word))
        BOS = False
    X.append(temp_X)
    y.append(temp_y)

X_fold0 = []
X_fold1 = []
X_fold2 = []
X_fold3 = []
X_fold4 = []

y_fold0 = []
y_fold1 = []
y_fold2 = []
y_fold3 = []
y_fold4 = []

X_folds = [ X_fold0, X_fold1, X_fold2, X_fold3, X_fold4 ]

y_folds = [ y_fold0, y_fold1, y_fold2, y_fold3, y_fold4 ]

for index, sentence in enumerate(X):
    X_folds[index % 5].append(sentence)

for index, label in enumerate(y):
    y_folds[index % 5].append(label)

print(len(X_folds), len(X_folds[0]), len(y_folds), len(y_folds[0]))

results = {}

for testFold in range(4):
    X_train = []
    y_train = []

    for index, fold in enumerate(X_folds):
        if index != testFold:
            X_train += fold

    for index, labels in enumerate(y_folds):
        if index != testFold:
            y_train += labels

    X_test = X_folds[testFold]
    y_test = y_folds[testFold]

    # print( len(X_train), len(y_train), len(X_test), len(y_test))

    crf = sklearn_crfsuite.CRF(
        algorithm='lbfgs',
        c1=0.1,
        c2=0.1,
        max_iterations=100,
        all_possible_transitions=True, )
    
    crf.fit(X_train, y_train)
    
    labels = list(crf.classes_)
    sorted_labels = sorted( labels, key=lambda name: (name[1:], name[0]))

    predictions = crf.predict(X_test)

    results[testFold] = [   metrics.flat_accuracy_score(y_test, predictions),
                            metrics.flat_f1_score(y_test, predictions, average="weighted"),
                            metrics.flat_precision_score(y_test, predictions, average="weighted"),
                            metrics.flat_recall_score(y_test, predictions, average="weighted")
                        
                        ]

    print( "TestFold is:", testFold ," --> Flat f1 score:", metrics.flat_f1_score(y_test, predictions, average="weighted") )

    print( metrics.flat_classification_report( y_test, predictions, labels=sorted_labels, digits=3) )

results

def print_transitions(trans_features):
    for (label_from, label_to), weight in trans_features:
        print("%-6s -> %-7s %0.6f" % (label_from, label_to, weight))

print("Top likely transitions:")
print_transitions(Counter(crf.transition_features_).most_common(20))

print("\nTop unlikely transitions:")
print_transitions(Counter(crf.transition_features_).most_common()[-20:])

"""# RandomizedSearchCV"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # define fixed parameters and parameters to search
# crf = sklearn_crfsuite.CRF(
#     algorithm='lbfgs',
#     max_iterations=100,
#     all_possible_transitions=True
# )
# params_space = {
#     'c1': scipy.stats.expon(scale=0.5),
#     'c2': scipy.stats.expon(scale=0.05),
# }
# 
# # use the same metric for evaluation
# f1_scorer = make_scorer(metrics.flat_f1_score,
#                         average='weighted')
# 
# # search
# rs = RandomizedSearchCV(crf, params_space,
#                         cv=3,
#                         verbose=1,
#                         n_jobs=-1,
#                         n_iter=50,
#                         scoring=f1_scorer)
# rs.fit(X_train, y_train)

# crf = rs.best_estimator_
print('best params:', rs.best_params_)
print('best CV score:', rs.best_score_)
print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

crf = sklearn_crfsuite.CRF(
    algorithm='lbfgs',
    c1=0.01922045471930707,
    c2=0.03690599493041812,
    max_iterations=100,
    all_possible_transitions=True, )

crf.fit(X_train, y_train)

labels = list(crf.classes_)
sorted_labels = sorted( labels, key=lambda name: (name[1:], name[0]))

predictions = crf.predict(X_test)

print( "Flat f1 score:", metrics.flat_f1_score(y_test, predictions, average="weighted") )

print( metrics.flat_classification_report( y_test, predictions, labels=sorted_labels, digits=3) )

def print_transitions(trans_features):
    for (label_from, label_to), weight in trans_features:
        print("%-6s -> %-7s %0.6f" % (label_from, label_to, weight))

print("Top likely transitions:")
print_transitions(Counter(crf.transition_features_).most_common(20))

print("\nTop unlikely transitions:")
print_transitions(Counter(crf.transition_features_).most_common()[-20:])